---
title: "HW 5"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(rvest)
library(lattice)
library("animation")
library("magrittr")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() +  theme(legend.position = "bottom"))

options(
  ggplots2.continuous.color = "viridis",
  ggplots2.continuous.fill = "viridus"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d


```

## Problem 1

Read in the data.
```{r, message=FALSE}
homicide_df = 
  read_csv("homicide-data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") # data entry error =1, affter arrange we get rid of it 
```

Let's look at this a bit.
```{r, message=FALSE}
aggregate_df =
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?
```{r, message=FALSE}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate...
```{r, message=FALSE}
results_df =
aggregate_df %>% 
  mutate(
    prop.tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)), # x is number of success and n is total number
    tidy_tests = map(.x = prop.tests, ~broom::tidy(.x))
    ) %>% 
 # %>% pull(prop.tests) delete tidy_tests in mutate then do this
  select(-prop.tests) %>% 
  unnest(tidy_tests) %>%  #show the test tibble
  select(city_state, estimate, conf.low, conf.high)
```


```{r, message=FALSE}
results_df %>% 
  mutate(city_state = fct_reorder(city_state,estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
  
```


```{r, error = TRUE}
city_prop_test = function(df){
  n_unsolved...
  n_total...
  prop.test(...)
} ##amother way to solve this problem

homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% # data entry error =1, affter arrange we get rid of it 
  nest(data = resolved)
```



## Problem 2

take a look at 1 csv file
```{r, message=FALSE}
data_1 = read_csv("lda_data/con_01.csv")
```

make the tibble and tidy the results
```{r, message=FALSE}
tidy_df =
tibble(
path = list.files("lda_data")
) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = purrr::map(.x = path, ~ read_csv(.x))) %>% 
    unnest(data) %>% 
  separate(path, into = c("path", "other"), sep= "/") %>% 
  separate(other, into = c("arm", "rest"), sep= "_") %>% 
  separate(rest, into = c("subject_ID", "remain"), sep= 2) %>% 
  select(-path, -remain) %>% 
    pivot_longer(
    week_1:week_8,
    names_to = "time",
    values_to = "observations"
    ) %>% 
  mutate(
    arm = str_replace(arm, "con", "control"),
    arm = str_replace(arm, "exp", "experimental")
  ) %>% 
  separate(time, into = c("name", "week"), sep= "_") %>% 
  select(-name)
  

control_arm_df = 
tidy_df %>% 
  filter(arm == "control") %>% 
  rename(control_arm = arm)
```

make the spaghetti plot
```{r, message=FALSE}

tidy_df %>% 
  group_by(arm) %>% 
ggplot(aes(x=week, y=observations, group = subject_ID, color=factor(subject_ID))) +
  geom_path(alpha = 0.7) + 
  geom_point(alpha = 0.7) +
  facet_grid(.~arm)

# + scale_color_hue(name = "subject_ID") ## only for discrete data
```

In these two time-series plots, both control and experimental groups' observations are oscillating. The trend of control group's observations are flat over time. However, as the time increases, the experimental group's observations are increasing.


## Problem 3

write a hypothesis function
```{r, message=FALSE}
hypothesis= function(sample_size = 30, mu, sigma = 5) { 
  sim_data = 
  tibble(
    x = rnorm(n = sample_size, mean = mu, sd = sigma)
  )
  
    t.test(sim_data, 
           alternative = "two.sided",
           mu = 0, paired = FALSE, 
           var.equal = FALSE, 
           conf.level = 0.95) %>% 
            broom::tidy() %>% 
      select(estimate, p.value)

}
```

function validation
```{r}
hypothesis(30, 0, 5)
```

Create 5000 datasets for hypothesis test mu = 0 iteration 
```{r}
output = vector("list", length = 5000)

for (i in 1:5000){
  output[[i]] = hypothesis(mu = 0)
} 

bind_rows(output)
```

Create 5000 datasets for hypothesis t.test(mu = 0) with true mu = 0:6 iteration 
```{r}
sim_results =
  tibble(mu = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun (5000, hypothesis(mu = .x))),
    estimate_df = map(output_lists, bind_rows)
    ) %>% 
  select(mu, estimate_df) %>% 
  unnest(estimate_df) %>% 
  rename(mu_hat = estimate)
```

make plots!
```{r}
plot1_df = 
sim_results %>% 
  mutate(
    decision_rule = case_when(
      p.value < 0.05  ~ "reject_null",
      p.value >= 0.05 ~ "fail_to_reject",
    )
  ) %>% 
  group_by(mu) %>% 
    count(decision_rule) %>% 
  filter(decision_rule == "reject_null") %>% 
  mutate(
    proportion = n/5000
  )

plot1_df %>% 
ggplot(aes(x=mu, y=proportion, group = 1, color = factor(mu))) +
  geom_path() + 
  geom_point() +
  labs(x = "true mean(mu)", 
       y = "proportion of reject_null", 
       title = "the power of the test vs true mean")
```

Overlay plots!!
```{r}
plot2_df = 
sim_results %>% 
  mutate(
    decision_rule = case_when(
      p.value < 0.05  ~ "reject_null",
      p.value >= 0.05 ~ "fail_to_reject"
    )) %>% 
  group_by(mu) %>% 
  summarize(
    mean_mu_hat = mean(mu_hat)
  )

plot3_df = 
sim_results %>% 
  mutate(
    decision_rule = case_when(
      p.value < 0.05  ~ "reject_null",
      p.value >= 0.05 ~ "fail_to_reject"
    )) %>% 
  filter(decision_rule == "reject_null") %>% 
  group_by(mu) %>% 
  summarize(
    mean_mu_hat = mean(mu_hat)
  )

ggplot(plot2_df, aes(x = mu, y = mean_mu_hat)) +
  geom_path(color = "red") + 
  geom_point(color = "red") +
  geom_path(plot3_df, mapping = aes(x = mu, y = mean_mu_hat)) + 
  geom_point(plot3_df, mapping = aes(x = mu, y = mean_mu_hat)) +
  labs(x = "true mean(mu)", 
       y = "average estimate of mu_hat ", 
       title = "average estimate of mu_hat vs true mean")   


#The red line is the average estimate of mu_hat vs the true value of true mean.

#The black line is the average estimate of mu_hat only in samples for which the null was rejected vs the true mean.
```

When true mean mu is from 0 to 3, the sample average of mu_hat across tests for which the null is rejected not approximately equal to the true value of mu. True mean(mu) and mean_mu_hat are different from each other because power is small. This means Type II error is big since power = 1-beta(Type II error).

When true mean mu is from 4 to 6, the sample average of mu_hat across tests for which the null is rejected approximately equal to the true value of mu. 

As the true mean mu increase, the proportion of times the null was rejected is higher and true mean(mu) almost equal to mean_mu_hat. This happens because power is large, which means type II error is small. 

We can see how does the power changes as the true mean(mu) increase from the following table.
```{r}
power_table =
plot1_df %>% 
  rename(power = proportion)
knitr::kable(power_table, title = "power table for mu from 0 to 6")

#notes:
#Power = 1 â€“ beta(type II error). Significance level = 1 - alpha(Type I error). In reality, we want both Type I and Type II errors to be small. In terms of significance level and power, which means we want a larger significance level and a large power. 

#Type 2 error (failing to reject a false null hypothesis) can be minimized either by picking a larger sample size or by choosing a "threshold" alternative value of the parameter in question that is further from the null value.
```







